{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcb254c",
   "metadata": {},
   "source": [
    "   # EXPLORE Data Science Academy Classification Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07538481",
   "metadata": {},
   "source": [
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**Oluwasola Osatuyi**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2addd",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "\n",
    "With such a multilingual population, it is only obvious that our systems and devices also communicate in multi-languages.\n",
    "\n",
    "In this challenge, you will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e231075",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d82a85a5",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we imported and briefly discussed the libraries that will be used throughout the analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc08e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (1.8.2.2)\n",
      "Requirement already satisfied: matplotlib in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: pillow in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (0.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e05f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textcleaner\n",
      "  Downloading textcleaner-0.4.26.tar.gz (4.9 kB)\n",
      "Requirement already satisfied: nltk in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from textcleaner) (3.7)\n",
      "Requirement already satisfied: regex in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from textcleaner) (2022.3.15)\n",
      "Requirement already satisfied: click in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from nltk->textcleaner) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from nltk->textcleaner) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/niye/opt/anaconda3/lib/python3.9/site-packages (from nltk->textcleaner) (4.64.0)\n",
      "Building wheels for collected packages: textcleaner\n",
      "  Building wheel for textcleaner (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for textcleaner: filename=textcleaner-0.4.26-py3-none-any.whl size=4738 sha256=0d7dae31f41fab573c40500c5afe6b4e2dfffd56f1118bdaaacd2daa534f11e9\n",
      "  Stored in directory: /Users/niye/Library/Caches/pip/wheels/93/ec/77/1e01212f4b7806e9b3397ed800d856162ccac962c1412df65d\n",
      "Successfully built textcleaner\n",
      "Installing collected packages: textcleaner\n",
      "Successfully installed textcleaner-0.4.26\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textcleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d0e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: '1.1.0.'\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn 1.1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04b48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visualisation\n",
    "import pandas as pd      \n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#Importing pre-process packages\n",
    "import re\n",
    "import nltk   #Importing nltk for preprocessing the datasets\n",
    "from nltk.corpus import stopwords  #importing Stopwords\n",
    "sns.set()   # setting plot style\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "\n",
    "#Importing data engineering packages\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Model performance metric libraries\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Importing comet library\n",
    "from comet_ml import Experiment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b6294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textcleaner as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7568ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64e5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d66b1bd",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we are going to load the data from the `train` and  `test_with_no_labels` file into DataFrames. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa58f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the train dataset\n",
    "df_train = pd.read_csv('train_set.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc403ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d15d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the test dataset\n",
    "df_test = pd.read_csv('test_set.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76798f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5682, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6e9bb",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Pre-processing of the datasets\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Pre-processing of the datasets ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we are going to perform thorough cleaning of the dataset. Since it is text data, we are going to use the Natural Language Processor (NLP) for this pre-process phase.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60de6ffa",
   "metadata": {},
   "source": [
    "# TRAIN DATASET PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd94f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = []\n",
    "for i, row in df_train.iterrows():\n",
    "    for text in row['text'].split('|||'):\n",
    "        all_train.append([row['lang_id'], text])\n",
    "all_train = pd.DataFrame(all_train, columns=['lang_id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3317963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22f6fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_train['lang_id'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a931fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing noise from the train dataset\n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'\n",
    "all_train['text'] = all_train['text'].replace(to_replace = pattern_url, value = subs_url, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2be38386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the train dataset to see if the noise were removed\n",
    "all_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c63f222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all train text to lower case \n",
    "all_train['text'] = all_train['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a327129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for removing punctuation\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([j for j in text if j not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fd7c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation from train dataset\n",
    "all_train['text'] = all_train['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde6b739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maikemisetso a magolo a lenaneo ke go phasalatsa ditlamelo le ditshono tsa dikgwebo go maatlafatsa ikonomi ya baagi ba selegae gore ba kgone go itumelela melemo ya ditshono tsa leruri tsa ditiro le seemo se se tokafetseng sa botshelo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if punctuation from the train dataset has been removed\n",
    "all_train['text'].iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "444fb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the tokeniser\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "\n",
    "tokenised_words = all_train['text'].apply(lambda x: x.split()) #Tokenising the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9dcc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train['tokens'] = tokenised_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74fcf857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['khomishini',\n",
       " 'ya',\n",
       " 'ndinganyiso',\n",
       " 'ya',\n",
       " 'mbeu',\n",
       " 'yo',\n",
       " 'ewa',\n",
       " 'maana',\n",
       " 'u',\n",
       " 'ya',\n",
       " 'nga',\n",
       " 'mulayo',\n",
       " 'wa',\n",
       " 'khomishini',\n",
       " 'ya',\n",
       " 'ndinganyiso',\n",
       " 'ya',\n",
       " 'mbeu',\n",
       " 'u',\n",
       " 'thetshelesa',\n",
       " 'mbilaelo',\n",
       " 'dzine',\n",
       " 'dza',\n",
       " 'tshimbilelana',\n",
       " 'na',\n",
       " 'tshialula',\n",
       " 'u',\n",
       " 'ya',\n",
       " 'nga',\n",
       " 'mbeu',\n",
       " 'nahone',\n",
       " 'i',\n",
       " 'ivhea',\n",
       " 'sa',\n",
       " 'foramu',\n",
       " 'ya',\n",
       " 'thungo',\n",
       " 'u',\n",
       " 'ya',\n",
       " 'nga',\n",
       " 'mulayo',\n",
       " 'wa',\n",
       " 'ndinganyiso']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train['tokens'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f50684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):    \n",
    "    return [t for t in tokens if t not in stopwords.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_train['stem'] = all_train['tokens'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train['stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_words = all_train['stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the stemmer to stem words in the two dataset\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#stemming the words from the train data\n",
    "tokenised_words = tokenised_words.apply(lambda sentence: [stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the Lemmmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc742c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatizing the train data\n",
    "tokenised_words = tokenised_words.apply(lambda sentence: [lemmatizer.lemmatize(word) for word in sentence])\n",
    "tokenised_words.head() #Checking to see if Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the cleaned message column into single sentence for the train dataset\n",
    "for i in range(len(tokenised_words)):\n",
    "    tokenised_words[i] = \" \".join(tokenised_words[i])\n",
    "all_train['cleaned'] = tokenised_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ec67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train.head() #checking to see if well combined into sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b0c93",
   "metadata": {},
   "source": [
    "## TEST DATASET PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88863b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing noise from the test dataset\n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'\n",
    "df_test['text'] = df_test['text'].replace(to_replace = pattern_url, value = subs_url, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the train dataset to see if the noise were removed\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf15bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all test text to lower case \n",
    "df_test['text'] = df_test['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation from test dataset\n",
    "df_test['text'] = df_test['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a046b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if punctuation from the test dataset has been removed\n",
    "df_test['text'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca9c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenising the test data\n",
    "tokenised_test = df_test['text'].apply(lambda x: x.split()) #Tokenising the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['tokens'] = tokenised_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['tokens'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1384328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords from the test data\n",
    "df_test['stem'] = df_test['tokens'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a41195",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_test = df_test['stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming the words from the test data\n",
    "tokenised_test = tokenised_test.apply(lambda sentence: [stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fb28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatizing the test data\n",
    "tokenised_tweet_test = tokenised_tweet_test.apply(lambda sentence: [lemmatizer.lemmatize(word) for word in sentence])\n",
    "tokenised_tweet_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the cleaned message column into single sentence for the test dataset\n",
    "for j in range(len(tokenised_tweet_test)):\n",
    "    tokenised_test[j] = \" \".join(tokenised_ttest[j])\n",
    "df_test['cleaned'] = tokenised_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9186c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head() #checking to see if well combined into sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82401af3",
   "metadata": {},
   "source": [
    "## EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec918d8",
   "metadata": {},
   "source": [
    "In this section we are going to perform an in-depth analysis of all the variables in the DataFrame. This would give us proper knowledge of our predictor variables to know if they are useful in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using NLP to clean this dataset \n",
    "sentiment_labels = list(df_train.sentiment.unique())\n",
    "sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235aee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sentiment'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b855a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate minority and majority classes\n",
    "neutral = df_train[df_train['sentiment']==0]\n",
    "believe = df_train[df_train['sentiment']==1]\n",
    "not_believe = df_train[df_train['sentiment']== -1]\n",
    "news = df_train[df_train['sentiment']== 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "believe_percent = len(believe)/ (len(neutral)+len(believe)+len(not_believe)+len(news))\n",
    "believe_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4092fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_believe_percent = len(not_believe)/ (len(neutral)+len(believe)+len(not_believe)+len(news))\n",
    "not_believe_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b975d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = len(neutral)/ (len(neutral)+len(believe)+len(not_believe)+len(news))\n",
    "neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e2075",
   "metadata": {},
   "source": [
    "From the above analysis, we can see that the classes in our ressponse variable is not balanced. Therefore we need to balance it during the Data Engineering part of our work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137fe51",
   "metadata": {},
   "source": [
    "## VISUALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualising the frequent words\n",
    "all_words = \" \".join([sentence for sentence in all_train['cleaned']])\n",
    "wordcloud = WordCloud(width= 800, height = 500, random_state= 42, max_font_size= 100).generate(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ploting the graph\n",
    "plt.figure(figsize = (15, 8))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e835cc",
   "metadata": {},
   "source": [
    "Frequent Words used by believers of climate change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca92e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77306dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dde9648",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e9cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87edf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e6fcbef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ef957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075f4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175368ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6caf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b820ba75",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we are going to: clean the dataset, and possibly create new features - as identified in the EDA phase. This is the phase where we drop the features we identified to drop in the EDA phase|\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e628ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the cleaned text from the trained data\n",
    "cv = CountVectorizer(max_features= 10000, ngram_range=(1,2))\n",
    "bow = cv.fit_transform(all_train['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed72b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the cleaned text from the test data\n",
    "bow_test = cv.transform(df_test['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca16ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting our data\n",
    "X = bow\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f580bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE(random_state = 1, k_neighbors = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = smt.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9cffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69de39f",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a> \n",
    "\n",
    "---\n",
    "\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, we created regression models that are able to accurately predict the three hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18397cd",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c664110",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, \n",
    "random_state = 42, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training using logistic regression\n",
    "#model = LogisticRegression(multi_class='ovr')\n",
    "model = LogisticRegression(random_state=42, solver='lbfgs', multi_class='multinomial')\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d619baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48debad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the unseen data\n",
    "model.fit(X, y)\n",
    "pred_test = model.predict(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af46e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model = pd.DataFrame(pred_test, columns= ['text'])\n",
    "result_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdc9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "503a71cd",
   "metadata": {},
   "source": [
    "## CatBoost Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training using catboost model classifier\n",
    "rf2_2 = CatBoostClassifier(\n",
    "                          bootstrap_type=\"Bernoulli\",\n",
    "                          class_weights=[1, 1, 1, 1],\n",
    "                          loss_function='MultiClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2_2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "y_pred = rf2_2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2_2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = rf2_2.predict(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cat = pd.DataFrame(y_pred_test, columns= ['text'])\n",
    "result_cat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed070ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8cc2f18",
   "metadata": {},
   "source": [
    "## Decision Tree Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification\n",
    "tree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f540f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f91709",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd8d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bede57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred_test = tree.predict(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tree = pd.DataFrame(tree_pred_test, columns= ['text'])\n",
    "result_tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae375e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c207cfec",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0925e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49642aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cac13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(x_train,y_train)\n",
    "svc_pred_test = svc.predict(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_svc = pd.DataFrame(svc_pred_test, columns= ['text'])\n",
    "result_svc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01cc24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96f48d5b",
   "metadata": {},
   "source": [
    "## Voting Ensemble Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble = VotingClassifier(estimators=[('lr', model), ('dt', tree), (\"svm\", svc)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e407f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4246aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensmb_pred = model_ensemble.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble.fit(x_train,y_train)\n",
    "esmb_pred_test = model_ensemble.predict(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0663fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_esmb = pd.DataFrame(esmb_pred_test, columns= ['sentiment'])\n",
    "result_esmb.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9cd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"tweetid\":df_test['tweetid']})\n",
    "submission_esmb = output.join(result_esmb)\n",
    "submission_esmb.to_csv(\"submission_esmb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da284f4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36883dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f895e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a0dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2de36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff267ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62e5a289",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section the relative performance of the various trained ML models on a holdout dataset was carried out. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9fac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb22f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b5573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0ca75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34c706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777f93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e22d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee1c9675",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1667e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2b807f",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 8. Conclusion\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9873c3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23be374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a750fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ae15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67771cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956d5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b87d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc87e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70312c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec3354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10ff09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79514711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c141fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b36024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af956f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b700d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0ff34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafa43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390fb53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38cea15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
